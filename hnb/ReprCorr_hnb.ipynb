{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just writing `__init__`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "from itertools import product as p\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from os.path import basename, dirname\n",
    "#import dask.array as da\n",
    "import pickle\n",
    "from var import fname2mname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvec(t, ar_mask=False):\n",
    "    if ar_mask:\n",
    "        ar = np.tril(t.cpu().numpy())\n",
    "        t = torch.FloatTensor(ar)\n",
    "    return t/t.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "self = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_heads_d = {} # {fname, int}\n",
    "self.attentions_d = {} # {fname, tensor}\n",
    "f1, f2, f3 = \"foo\", \"bar\", \"baz\"\n",
    "attention_fname_l = [f1, f2, f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize `num_heads_d`, `attentions_d` with fake data\n",
    "n1, n2, n3 = 10, 12, 14\n",
    "wlen_l = [12, 5, 9, 6]\n",
    "\n",
    "self.num_heads_d[f1] = n1\n",
    "self.num_heads_d[f2] = n2\n",
    "self.num_heads_d[f3] = n3\n",
    "\n",
    "for fname in attention_fname_l:\n",
    "    attentions_l = [pvec(torch.randn(self.num_heads_d[fname], wlen, wlen), True)\n",
    "                        for wlen in wlen_l]\n",
    "    self.attentions_d[fname] = attentions_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set `self.representations_d` loop\n",
    "self.representations_d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary values of loop vars\n",
    "network = f1\n",
    "al = self.attentions_d[network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fal = [torch.flatten(at, start_dim=1).t()\n",
    "          for at in al]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cat(fal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    self.representations_d[network] = t[self.unmask_ix, :]\n",
    "except:\n",
    "    self.unmask_ix = torch.prod(t!=0, dim=1, dtype=torch.uint8)\n",
    "    self.representations_d[network] = t[self.unmask_ix, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.prod?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full loop\n",
    "for network, al in self.attentions_d.items():\n",
    "    fal = [torch.flatten(at, start_dim=1).t() for at in al]\n",
    "    t = torch.cat(fal)\n",
    "    try:\n",
    "        self.representations_d[network] = t[self.unmask_ix, :]\n",
    "    except:\n",
    "        self.unmask_ix = torch.prod(t!=0, dim=1, dtype=torch.uint8)\n",
    "        self.representations_d[network] = t[self.unmask_ix, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00],\n",
       "        [-1.4418e+00,  2.5404e-01,  6.8427e+00,  ...,  1.9495e+00,\n",
       "          8.1728e-01,  1.7711e-01],\n",
       "        [ 2.4418e+00,  7.4596e-01, -5.8427e+00,  ..., -9.4947e-01,\n",
       "          1.8272e-01,  8.2289e-01],\n",
       "        ...,\n",
       "        [ 9.2903e-02,  9.3986e-02, -1.6145e+01,  ..., -7.6977e-01,\n",
       "         -2.0881e-02,  4.9943e-01],\n",
       "        [ 4.2358e-01,  2.1570e-01,  2.1104e+01,  ...,  1.8191e+00,\n",
       "          1.2769e-01,  6.0012e-01],\n",
       "        [-1.1533e-01,  2.7871e-01,  6.1639e+00,  ...,  1.1590e+00,\n",
       "          1.3368e-01,  9.3693e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.representations_d[f1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
