{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "from itertools import product as p\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from os.path import basename, dirname\n",
    "#import dask.array as da\n",
    "import pickle\n",
    "from var import fname2mname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvec(t):\n",
    "    return t/t.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "self = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_heads_d = {} # {fname, int}\n",
    "self.attentions_d = {} # {fname, tensor}\n",
    "f1, f2, f3 = \"foo\", \"bar\", \"baz\"\n",
    "attention_fname_l = [f1, f2, f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize `num_heads_d`, `attentions_d` with fake data\n",
    "n1, n2, n3 = 10, 12, 14\n",
    "wlen_l = [12, 5, 9, 6]\n",
    "\n",
    "self.num_heads_d[f1] = n1\n",
    "self.num_heads_d[f2] = n2\n",
    "self.num_heads_d[f3] = n3\n",
    "\n",
    "for fname in attention_fname_l:\n",
    "    attentions_l = [pvec(torch.randn(self.num_heads_d[fname], wlen, wlen))\n",
    "                        for wlen in wlen_l]\n",
    "    self.attentions_d[fname] = attentions_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.device = torch.device('cpu')\n",
    "self.op = min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = self.device\n",
    "\n",
    "self.corrs = {network: {} for network in self.attentions_d}\n",
    "self.pairs = {network: {} for network in self.attentions_d}\n",
    "self.similarities = {network: {} for network in\n",
    "                     self.attentions_d}\n",
    "num_sentences = len(next(iter(self.attentions_d.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `self.corrs`, `self.pairs`, `self.similarities` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily set loop variables\n",
    "network = f1\n",
    "other_network = f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.zeros((num_sentences, self.num_heads_d[network], self.num_heads_d[other_network]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set `distances` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary loop variables\n",
    "idx = 0\n",
    "attns = self.attentions_d[network][0]\n",
    "o_attns = self.attentions_d[other_network][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = attns.to(device)\n",
    "t2 = o_attns.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t11, t12, t13 = t1.size()\n",
    "t21, t22, t23 = t2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1.reshape(t11, 1, t12, t13)\n",
    "t2 = t2.reshape(1, t21, t22, t23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = torch.norm(t1-t2, p='fro', dim=(2,3))\n",
    "distance = distance.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[idx] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full\n",
    "for idx, (attns, o_attns) in enumerate(zip(self.attentions_d[network], self.attentions_d[other_network])):\n",
    "    t1 = attns.to(device)\n",
    "    t2 = o_attns.to(device)\n",
    "    t11, t12, t13 = t1.size()\n",
    "    t21, t22, t23 = t2.size()\n",
    "    t1 = t1.reshape(t11, 1, t12, t13)\n",
    "    t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "    distance = torch.norm(t1-t2, p='fro', dim=(2,3))\n",
    "    distances[idx] = distance.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `correlation`\n",
    "distances = distances.mean(axis=0)\n",
    "mi, ma = distances.min(), distances.max()\n",
    "distances = (distances-mi)/(ma-mi)\n",
    "correlation = 1 - distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main update\n",
    "self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "self.pairs[other_network][network] = correlation.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "correlate: 100%|█████████████████████████████| 9/9 [00:00<00:00, 6202.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# full loop\n",
    "for network, other_network in tqdm(p(self.attentions_d,\n",
    "                                     self.attentions_d),\n",
    "                                     desc='correlate',\n",
    "                                     total=len(self.attentions_d)**2):\n",
    "    if network == other_network:\n",
    "        continue\n",
    "\n",
    "    if other_network in self.corrs[network]: \n",
    "        continue\n",
    "        \n",
    "    # Set `distances`\n",
    "    distances = np.zeros((num_sentences, self.num_heads_d[network], self.num_heads_d[other_network]))\n",
    "    for idx, (attns, o_attns) in enumerate(zip(self.attentions_d[network], self.attentions_d[other_network])):\n",
    "        t1 = attns.to(device)\n",
    "        t2 = o_attns.to(device)\n",
    "        t11, t12, t13 = t1.size()\n",
    "        t21, t22, t23 = t2.size()\n",
    "        t1 = t1.reshape(t11, 1, t12, t13)\n",
    "        t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "        distance = torch.norm(t1-t2, p='fro', dim=(2,3))\n",
    "        distances[idx] = distance.cpu().numpy()\n",
    "        \n",
    "    # Set `correlation`\n",
    "    distances = distances.mean(axis=0)\n",
    "    mi, ma = distances.min(), distances.max()\n",
    "    distances = (distances-mi)/(ma-mi)\n",
    "    correlation = 1 - distances\n",
    "    \n",
    "    # Main update\n",
    "    self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "    self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "    self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "    self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "    self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "    self.pairs[other_network][network] = correlation.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(self):\n",
    "    # convenient variables\n",
    "    device = self.device\n",
    "    num_sentences = len(next(iter(self.attentions_d.values())))\n",
    "\n",
    "    # Set `self.corrs` : {network: {other: [corr]}}\n",
    "    # Set `self.pairs` : {network: {other: [pair]}}\n",
    "    # pair is index of head in other network\n",
    "    # Set `self.similarities` : {network: {other: sim}}\n",
    "    self.corrs = {network: {} for network in self.attentions_d}\n",
    "    self.pairs = {network: {} for network in self.attentions_d}\n",
    "    self.similarities = {network: {} for network in self.attentions_d}\n",
    "    for network, other_network in tqdm(p(self.attentions_d,\n",
    "                                         self.attentions_d),\n",
    "                                         desc='correlate',\n",
    "                                         total=len(self.attentions_d)**2):\n",
    "        if network == other_network:\n",
    "            continue\n",
    "\n",
    "        if other_network in self.corrs[network]: \n",
    "            continue\n",
    "\n",
    "        # Set `distances`\n",
    "        distances = np.zeros((num_sentences, self.num_heads_d[network], self.num_heads_d[other_network]))\n",
    "        for idx, (attns, o_attns) in enumerate(zip(self.attentions_d[network], self.attentions_d[other_network])):\n",
    "            t1 = attns.to(device)\n",
    "            t2 = o_attns.to(device)\n",
    "            t11, t12, t13 = t1.size()\n",
    "            t21, t22, t23 = t2.size()\n",
    "            t1 = t1.reshape(t11, 1, t12, t13)\n",
    "            t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "            distance = torch.norm(t1-t2, p='fro', dim=(2,3))\n",
    "            distances[idx] = distance.cpu().numpy()\n",
    "\n",
    "        # Set `correlation`\n",
    "        distances = distances.mean(axis=0)\n",
    "        mi, ma = distances.min(), distances.max()\n",
    "        distances = (distances-mi)/(ma-mi)\n",
    "        correlation = 1 - distances\n",
    "\n",
    "        # Main update\n",
    "        self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "        self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "        self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "        self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "        self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "        self.pairs[other_network][network] = correlation.argmax(axis=0)\n",
    "\n",
    "    # Set `self.head_sort` : {network, sorted_list}\n",
    "    # Set `self.head_notated_sort` : {network: [(head, {other: (corr, pair)})]}\n",
    "    self.head_sort = {} \n",
    "    self.head_notated_sort = {}\n",
    "    for network in tqdm(self.attentions_d, desc='annotation'):\n",
    "        self.head_sort[network] = sorted(\n",
    "            range(self.num_heads_d[network]), \n",
    "            key=lambda i: self.op(\n",
    "                self.corrs[network][other][i] for other in self.corrs[network]\n",
    "            ), \n",
    "            reverse=True,\n",
    "        )\n",
    "        self.head_notated_sort[network] = [\n",
    "            (\n",
    "                head,\n",
    "                {\n",
    "                    other : (\n",
    "                        self.corrs[network][other][head], \n",
    "                        self.pairs[network][other][head],\n",
    "                    ) \n",
    "                    for other in self.corrs[network]\n",
    "                }\n",
    "            ) \n",
    "            for head in self.head_sort[network]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "correlate: 100%|█████████████████████████████| 9/9 [00:00<00:00, 4496.04it/s]\n",
      "annotation: 100%|████████████████████████████| 3/3 [00:00<00:00, 9939.11it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_correlations(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': {'bar': array([0.80571031, 0.89711243, 0.96516111, 0.96388111, 0.79245618,\n",
       "         0.98107638, 0.95147972, 0.90318424, 0.66177127, 1.        ]),\n",
       "  'baz': array([0.70828754, 0.8381147 , 0.9657241 , 0.97126409, 0.69442393,\n",
       "         0.98877343, 0.94589928, 0.85756298, 0.49796528, 1.        ])},\n",
       " 'bar': {'foo': array([0.51749251, 0.25547081, 0.93043385, 0.57637179, 0.75780165,\n",
       "         0.87522676, 0.29529897, 0.96944789, 0.82012099, 0.63578879,\n",
       "         0.90963748, 1.        ]),\n",
       "  'baz': array([0.4970413 , 0.25899628, 0.95184827, 0.5703824 , 0.75182914,\n",
       "         0.88623117, 0.28212633, 0.97411617, 0.83753652, 0.70851246,\n",
       "         0.91955914, 1.        ])},\n",
       " 'baz': {'foo': array([0.90670855, 0.98533472, 0.76424015, 0.85075476, 0.96583704,\n",
       "         0.90766268, 0.92603776, 0.88066662, 0.87295673, 1.        ,\n",
       "         0.99580053, 0.53103789, 0.91161257, 0.82553783]),\n",
       "  'bar': array([0.94825046, 0.98203163, 0.85541828, 0.90084108, 0.98183017,\n",
       "         0.93970805, 0.95202526, 0.91037505, 0.91237029, 1.        ,\n",
       "         0.99894184, 0.7122791 , 0.93318969, 0.89160531])}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.corrs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
