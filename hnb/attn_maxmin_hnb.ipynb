{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "from itertools import product as p\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from os.path import basename, dirname\n",
    "#import dask.array as da\n",
    "import pickle\n",
    "from var import fname2mname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvec(t):\n",
    "    return t/t.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "self = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_heads_d = {} # {fname, int}\n",
    "self.attentions_d = {} # {fname, tensor}\n",
    "f1, f2, f3 = \"foo\", \"bar\", \"baz\"\n",
    "attention_fname_l = [f1, f2, f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize `num_heads_d`, `attentions_d` with fake data\n",
    "n1, n2, n3 = 10, 12, 14\n",
    "wlen_l = [12, 5, 9, 6]\n",
    "\n",
    "self.num_heads_d[f1] = n1\n",
    "self.num_heads_d[f2] = n2\n",
    "self.num_heads_d[f3] = n3\n",
    "\n",
    "for fname in attention_fname_l:\n",
    "    attentions_l = [pvec(torch.randn(self.num_heads_d[fname], wlen, wlen))\n",
    "                        for wlen in wlen_l]\n",
    "    self.attentions_d[fname] = attentions_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.device = torch.device('cpu')\n",
    "self.op = min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FroMaxMinCorr, just our example\n",
    "def correlation_matrix(network, other_network):\n",
    "    device = self.device\n",
    "    num_sentences = self.num_sentences\n",
    "    \n",
    "    distances = np.zeros((num_sentences, self.num_heads_d[network], self.num_heads_d[other_network]))\n",
    "    for idx, (attns, o_attns) in enumerate(zip(self.attentions_d[network], self.attentions_d[other_network])):\n",
    "        t1 = attns.to(device)\n",
    "        t2 = o_attns.to(device)\n",
    "        t11, t12, t13 = t1.size()\n",
    "        t21, t22, t23 = t2.size()\n",
    "        t1 = t1.reshape(t11, 1, t12, t13)\n",
    "        t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "        distance = torch.norm(t1-t2, p='fro', dim=(2,3))\n",
    "        distances[idx] = distance.cpu().numpy()\n",
    "        \n",
    "    # Set `correlation`\n",
    "    distances = distances.mean(axis=0)\n",
    "    mi, ma = distances.min(), distances.max()\n",
    "    distances = (distances-mi)/(ma-mi)\n",
    "    correlation = 1 - distances\n",
    "    \n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.correlation_matrix = correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = self.device\n",
    "\n",
    "self.corrs = {network: {} for network in self.attentions_d}\n",
    "self.pairs = {network: {} for network in self.attentions_d}\n",
    "self.similarities = {network: {} for network in\n",
    "                     self.attentions_d}\n",
    "self.num_sentences = len(next(iter(self.attentions_d.values())))\n",
    "self.num_words = sum(t.size()[-1] for t in next(iter(self.attentions_d.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `self.corrs`, `self.pairs`, `self.similarities` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily set loop variables\n",
    "network = f1\n",
    "other_network = f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = self.correlation_matrix(network, other_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main update\n",
    "self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "self.pairs[other_network][network] = correlation.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "correlate: 100%|█████████████████████████████| 9/9 [00:00<00:00, 5287.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# full loop\n",
    "for network, other_network in tqdm(p(self.attentions_d,\n",
    "                                     self.attentions_d),\n",
    "                                     desc='correlate',\n",
    "                                     total=len(self.attentions_d)**2):\n",
    "    if network == other_network:\n",
    "        continue\n",
    "\n",
    "    if other_network in self.corrs[network]: \n",
    "        continue\n",
    "        \n",
    "    correlation = self.correlation_matrix(network, other_network)\n",
    "    \n",
    "    # Main update\n",
    "    self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "    self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "    self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "    self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "    self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "    self.pairs[other_network][network] = correlation.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(self):\n",
    "    # convenient variables\n",
    "    device = self.device\n",
    "    self.num_sentences = len(next(iter(self.attentions_d.values())))\n",
    "    self.num_words = sum(t.size()[-1] for t in next(iter(self.attentions_d.values())))\n",
    "\n",
    "    # Set `self.corrs` : {network: {other: [corr]}}\n",
    "    # Set `self.pairs` : {network: {other: [pair]}}\n",
    "    # pair is index of head in other network\n",
    "    # Set `self.similarities` : {network: {other: sim}}\n",
    "    self.corrs = {network: {} for network in self.attentions_d}\n",
    "    self.pairs = {network: {} for network in self.attentions_d}\n",
    "    self.similarities = {network: {} for network in self.attentions_d}\n",
    "    for network, other_network in tqdm(p(self.attentions_d,\n",
    "                                         self.attentions_d),\n",
    "                                         desc='correlate',\n",
    "                                         total=len(self.attentions_d)**2):\n",
    "        if network == other_network:\n",
    "            continue\n",
    "\n",
    "        if other_network in self.corrs[network]: \n",
    "            continue\n",
    "\n",
    "        correlation = self.correlation_matrix(network, other_network)\n",
    "\n",
    "        # Main update\n",
    "        self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "        self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "        self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "        self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "        self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "        self.pairs[other_network][network] = correlation.argmax(axis=0)\n",
    "\n",
    "    # Set `self.head_sort` : {network, sorted_list}\n",
    "    # Set `self.head_notated_sort` : {network: [(head, {other: (corr, pair)})]}\n",
    "    self.head_sort = {} \n",
    "    self.head_notated_sort = {}\n",
    "    for network in tqdm(self.attentions_d, desc='annotation'):\n",
    "        self.head_sort[network] = sorted(\n",
    "            range(self.num_heads_d[network]), \n",
    "            key=lambda i: self.op(\n",
    "                self.corrs[network][other][i] for other in self.corrs[network]\n",
    "            ), \n",
    "            reverse=True,\n",
    "        )\n",
    "        self.head_notated_sort[network] = [\n",
    "            (\n",
    "                head,\n",
    "                {\n",
    "                    other : (\n",
    "                        self.corrs[network][other][head], \n",
    "                        self.pairs[network][other][head],\n",
    "                    ) \n",
    "                    for other in self.corrs[network]\n",
    "                }\n",
    "            ) \n",
    "            for head in self.head_sort[network]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "correlate: 100%|█████████████████████████████| 9/9 [00:00<00:00, 4123.74it/s]\n",
      "annotation: 100%|████████████████████████████| 3/3 [00:00<00:00, 5043.25it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_correlations(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': {'bar': array([0.98086308, 0.90935966, 0.95885367, 0.84668847, 1.        ,\n",
       "         0.6859649 , 0.99684803, 0.82426914, 0.87466759, 0.96812032]),\n",
       "  'baz': array([0.99653077, 0.9896387 , 0.99414953, 0.98114855, 1.        ,\n",
       "         0.96047981, 0.99906089, 0.97768111, 0.98509738, 0.99635   ])},\n",
       " 'bar': {'foo': array([0.91008778, 0.31300565, 0.92151437, 0.83687101, 0.72204893,\n",
       "         0.97862211, 0.89750213, 0.88318838, 0.48930261, 0.93181968,\n",
       "         0.88392007, 1.        ]),\n",
       "  'baz': array([0.98914902, 0.91514913, 0.99059196, 0.98066529, 0.96687033,\n",
       "         0.99733577, 0.98778902, 0.98619307, 0.93834528, 0.99155758,\n",
       "         0.98664106, 1.        ])},\n",
       " 'baz': {'foo': array([0.99940343, 0.99812358, 0.99586541, 0.99183936, 0.03294723,\n",
       "         0.95344159, 0.98109539, 1.        , 0.98771851, 0.99633164,\n",
       "         0.97622873, 0.99829991, 0.98175752, 0.97234356]),\n",
       "  'bar': array([1.        , 0.99716084, 0.99547619, 0.99160533, 0.0855523 ,\n",
       "         0.95667934, 0.98149787, 0.99952981, 0.98847491, 0.99585092,\n",
       "         0.97740485, 0.99841447, 0.98349189, 0.97279401])}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.corrs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
