{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from itertools import product as p\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "self = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_neurons_d = {} # {fname, int}\n",
    "self.representations_d = {} # {fname, tensor}\n",
    "f1, f2, f3 = \"foo\", \"bar\", \"baz\"\n",
    "representation_files = [f1, f2, f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize `num_neurons_d`, `representations_d` with fake data\n",
    "n1, n2, n3 = 100, 80, 70\n",
    "nword = 1000\n",
    "t1 = torch.randn(nword, n1)\n",
    "t2 = torch.randn(nword, n2)\n",
    "t3 = torch.randn(nword, n3)\n",
    "self.num_neurons_d[f1] = n1\n",
    "self.num_neurons_d[f2] = n2\n",
    "self.num_neurons_d[f3] = n3\n",
    "self.representations_d[f1] = t1\n",
    "self.representations_d[f2] = t2\n",
    "self.representations_d[f3] = t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra params\n",
    "self.limit = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gram_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "X = torch.randn(10, 5)\n",
    "threshold = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_products = torch.mm(X, X.t())\n",
    "sq_norms = torch.diag(dot_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_distances = -2 * dot_products + sq_norms[:, None] + sq_norms[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  4.7684e-07, -9.5367e-07,  4.7684e-07,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.5367e-07],\n",
       "        [ 0.0000e+00,  0.0000e+00,  1.9073e-06,  9.5367e-07,  0.0000e+00,\n",
       "         -9.5367e-07,  1.9073e-06,  0.0000e+00, -1.9073e-06, -9.5367e-07],\n",
       "        [ 4.7684e-07,  1.9073e-06,  0.0000e+00,  0.0000e+00, -4.7684e-07,\n",
       "          0.0000e+00, -4.7684e-07,  2.3842e-07,  7.1526e-07,  0.0000e+00],\n",
       "        [-9.5367e-07,  9.5367e-07,  0.0000e+00,  0.0000e+00,  4.7684e-07,\n",
       "         -1.1921e-07,  0.0000e+00, -1.1921e-07,  0.0000e+00,  4.7684e-07],\n",
       "        [ 4.7684e-07,  0.0000e+00, -4.7684e-07,  4.7684e-07,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-9.5367e-07, -9.5367e-07,  4.7684e-07, -1.1921e-07,  0.0000e+00,\n",
       "          0.0000e+00, -4.7684e-07,  0.0000e+00,  9.5367e-07,  0.0000e+00],\n",
       "        [-9.5367e-07,  1.9073e-06, -4.7684e-07,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7684e-07,  9.5367e-07],\n",
       "        [-9.5367e-07,  0.0000e+00,  2.3842e-07, -1.1921e-07,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3842e-07,  0.0000e+00],\n",
       "        [ 9.5367e-07, -1.9073e-06,  7.1526e-07,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -4.7684e-07,  2.3842e-07,  0.0000e+00,  4.7684e-07],\n",
       "        [-9.5367e-07,  0.0000e+00,  0.0000e+00,  4.7684e-07,  0.0000e+00,\n",
       "          0.0000e+00,  9.5367e-07,  0.0000e+00,  4.7684e-07,  0.0000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.empty(10, 10)\n",
    "for i, j in p(range(10), range(10)):\n",
    "    Y[i, j] = torch.norm(X[i] - X[j])\n",
    "Y**2 - sq_distances # all small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7507, 0.5388, 0.4575, 0.6136, 0.3495, 0.4465, 0.3753, 0.4071,\n",
       "         0.4197],\n",
       "        [0.7507, 1.0000, 0.5407, 0.4774, 0.4748, 0.4795, 0.2608, 0.3665, 0.3235,\n",
       "         0.2975],\n",
       "        [0.5388, 0.5407, 1.0000, 0.8286, 0.6065, 0.5740, 0.5129, 0.7181, 0.8231,\n",
       "         0.7575],\n",
       "        [0.4575, 0.4774, 0.8286, 1.0000, 0.6817, 0.8463, 0.7088, 0.8859, 0.7702,\n",
       "         0.5360],\n",
       "        [0.6136, 0.4748, 0.6065, 0.6817, 1.0000, 0.6268, 0.6628, 0.4440, 0.5301,\n",
       "         0.6351],\n",
       "        [0.3495, 0.4795, 0.5740, 0.8463, 0.6268, 1.0000, 0.5055, 0.6384, 0.4547,\n",
       "         0.3281],\n",
       "        [0.4465, 0.2608, 0.5129, 0.7088, 0.6628, 0.5055, 1.0000, 0.6822, 0.6241,\n",
       "         0.4274],\n",
       "        [0.3753, 0.3665, 0.7181, 0.8859, 0.4440, 0.6384, 0.6822, 1.0000, 0.7662,\n",
       "         0.3774],\n",
       "        [0.4071, 0.3235, 0.8231, 0.7702, 0.5301, 0.4547, 0.6241, 0.7662, 1.0000,\n",
       "         0.6572],\n",
       "        [0.4197, 0.2975, 0.7575, 0.5360, 0.6351, 0.3281, 0.4274, 0.3774, 0.6572,\n",
       "         1.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_median_distance = torch.median(sq_distances)\n",
    "torch.exp(-sq_distances / (2 * threshold ** 2 * sq_median_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full\n",
    "def gram_rbf(X, threshold=1.0):\n",
    "    dot_products = torch.mm(X, X.t())\n",
    "    sq_norms = torch.diag(dot_products)\n",
    "    sq_distances = -2 * dot_products + sq_norms[:, None] + sq_norms[None, :]\n",
    "    sq_median_distance = torch.median(sq_distances)\n",
    "    return torch.exp(-sq_distances / (2 * threshold ** 2 * sq_median_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_gram(G):\n",
    "    means = G.mean(0, keepdim=False)\n",
    "    means -= means.mean() / 2\n",
    "    return G - means[None, :] - means[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `limit`\n",
    "n_words = next(iter(self.representations_d.values())).size()[0]\n",
    "if type(self.limit) == float:\n",
    "    limit = int(n_words * self.limit)\n",
    "elif type(self.limit) == int:\n",
    "    limit = self.limit\n",
    "else:\n",
    "    limit = self.limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `self.similarities`\n",
    "# {network: {other: rbfcka_similarity}}\n",
    "self.similarities = {network: {} for network in self.representations_d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loopvar\n",
    "network = f1\n",
    "other_network = f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if network == other_network:\n",
    "#     continue\n",
    "\n",
    "# if other_network in self.similarities[network]: \n",
    "#     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: random subset of data using limit?\n",
    "Gx = center_gram(gram_rbf(self.representations_d[network][:limit]))\n",
    "Gy = center_gram(gram_rbf(self.representations_d[other_network][:limit]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_hsic = torch.dot(Gx.view(-1), Gy.view(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_gx = torch.norm(Gx, p=\"fro\").item()\n",
    "norm_gy = torch.norm(Gy, p=\"fro\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = scaled_hsic / (norm_gx*norm_gy)\n",
    "self.similarities[network][other_network] = sim\n",
    "self.similarities[other_network][network] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rbfcka: 100%|â–ˆ| 9/9 [00:00<00:00, 111.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# full loop\n",
    "for network, other_network in tqdm(p(self.representations_d,\n",
    "                                             self.representations_d),\n",
    "                                           desc='rbfcka',\n",
    "                                           total=len(self.representations_d)**2):\n",
    "\n",
    "    if network == other_network:\n",
    "        continue\n",
    "\n",
    "    if other_network in self.similarities[network]: \n",
    "        continue\n",
    "\n",
    "    # TO DO: random subset of data using limit?\n",
    "    Gx = center_gram(gram_rbf(self.representations_d[network][:limit]))\n",
    "    Gy = center_gram(gram_rbf(self.representations_d[other_network][:limit]))\n",
    "\n",
    "    scaled_hsic = torch.dot(Gx.view(-1), Gy.view(-1)).item()\n",
    "\n",
    "    norm_gx = torch.norm(Gx, p=\"fro\").item()\n",
    "    norm_gy = torch.norm(Gy, p=\"fro\").item()\n",
    "\n",
    "    sim = scaled_hsic / (norm_gx*norm_gy)\n",
    "    self.similarities[network][other_network] = sim\n",
    "    self.similarities[other_network][network] = sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full\n",
    "def gram_rbf(X, threshold=1.0):\n",
    "    dot_products = torch.mm(X, X.t())\n",
    "    sq_norms = torch.diag(dot_products)\n",
    "    sq_distances = -2 * dot_products + sq_norms[:, None] + sq_norms[None, :]\n",
    "    sq_median_distance = torch.median(sq_distances)\n",
    "    return torch.exp(-sq_distances / (2 * threshold ** 2 * sq_median_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_gram(G):\n",
    "    means = G.mean(0, keepdim=False)\n",
    "    means -= means.mean() / 2\n",
    "    return G - means[None, :] - means[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(self):\n",
    "    # Set `limit`\n",
    "    n_words = next(iter(self.representations_d.values())).size()[0]\n",
    "    if type(self.limit) == float:\n",
    "        limit = int(n_words * self.limit)\n",
    "    elif type(self.limit) == int:\n",
    "        limit = self.limit\n",
    "    else:\n",
    "        limit = self.limit\n",
    "    \n",
    "    # Set `self.similarities`\n",
    "    # {network: {other: rbfcka_similarity}}\n",
    "    self.similarities = {network: {} for network in self.representations_d}\n",
    "    for network, other_network in tqdm(p(self.representations_d,\n",
    "                                             self.representations_d),\n",
    "                                           desc='rbfcka',\n",
    "                                           total=len(self.representations_d)**2):\n",
    "\n",
    "        if network == other_network:\n",
    "            continue\n",
    "\n",
    "        if other_network in self.similarities[network]: \n",
    "            continue\n",
    "\n",
    "        # TO DO: random subset of data using limit?\n",
    "        Gx = center_gram(gram_rbf(self.representations_d[network][:limit]))\n",
    "        Gy = center_gram(gram_rbf(self.representations_d[other_network][:limit]))\n",
    "\n",
    "        scaled_hsic = torch.dot(Gx.view(-1), Gy.view(-1)).item()\n",
    "        norm_gx = torch.norm(Gx, p=\"fro\").item()\n",
    "        norm_gy = torch.norm(Gy, p=\"fro\").item()\n",
    "\n",
    "        sim = scaled_hsic / (norm_gx*norm_gy)\n",
    "        self.similarities[network][other_network] = sim\n",
    "        self.similarities[other_network][network] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rbfcka: 100%|â–ˆ| 9/9 [00:00<00:00, 52.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': {'bar': 0.13177755107494116, 'baz': 0.12516603324836942},\n",
       " 'bar': {'foo': 0.13177755107494116, 'baz': 0.11312672037165297},\n",
       " 'baz': {'foo': 0.12516603324836942, 'bar': 0.11312672037165297}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nice\n",
    "compute_correlations(self)\n",
    "self.similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
