{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "from itertools import product as p\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from os.path import basename, dirname\n",
    "#import dask.array as da\n",
    "import pickle\n",
    "from var import fname2mname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvec(t, ar_mask=False):\n",
    "    if ar_mask:\n",
    "        ar = np.tril(t.cpu().numpy())\n",
    "        t = torch.FloatTensor(ar)\n",
    "    return t/t.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "self = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_heads_d = {} # {fname, int}\n",
    "self.attentions_d = {} # {fname, tensor}\n",
    "f1, f2, f3 = \"foo\", \"bar\", \"baz\"\n",
    "attention_fname_l = [f1, f2, f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize `num_heads_d`, `attentions_d` with fake data\n",
    "n1, n2, n3 = 10, 12, 14\n",
    "wlen_l = [27, 5, 9, 2]\n",
    "\n",
    "self.num_heads_d[f1] = n1\n",
    "self.num_heads_d[f2] = n2\n",
    "self.num_heads_d[f3] = n3\n",
    "\n",
    "for fname in attention_fname_l:\n",
    "    attentions_l = [pvec(torch.abs(torch.randn(self.num_heads_d[fname], wlen, wlen)), True)\n",
    "                        for wlen in wlen_l]\n",
    "    self.attentions_d[fname] = attentions_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.device = torch.device('cpu')\n",
    "self.op = min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_sentences = len(wlen_l)\n",
    "self.num_words = sum(wlen_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(self):\n",
    "    # convenient variables\n",
    "    device = self.device\n",
    "    self.num_sentences = len(next(iter(self.attentions_d.values())))\n",
    "    self.num_words = sum(t.size()[-1] for t in next(iter(self.attentions_d.values())))\n",
    "\n",
    "    # Set `self.corrs` : {network: {other: [corr]}}\n",
    "    # Set `self.pairs` : {network: {other: [pair]}}\n",
    "    # pair is index of head in other network\n",
    "    # Set `self.similarities` : {network: {other: sim}}\n",
    "    self.corrs = {network: {} for network in self.attentions_d}\n",
    "    self.pairs = {network: {} for network in self.attentions_d}\n",
    "    self.similarities = {network: {} for network in self.attentions_d}\n",
    "    for network, other_network in tqdm(p(self.attentions_d,\n",
    "                                         self.attentions_d),\n",
    "                                         desc='correlate',\n",
    "                                         total=len(self.attentions_d)**2):\n",
    "        if network == other_network:\n",
    "            continue\n",
    "\n",
    "        if other_network in self.corrs[network]: \n",
    "            continue\n",
    "\n",
    "        correlation = self.correlation_matrix(network, other_network)\n",
    "\n",
    "        # Main update\n",
    "        self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "        self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "        self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "        self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "        self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "        self.pairs[other_network][network] = correlation.argmax(axis=0)\n",
    "\n",
    "    # Set `self.head_sort` : {network, sorted_list}\n",
    "    # Set `self.head_notated_sort` : {network: [(head, {other: (corr, pair)})]}\n",
    "    self.head_sort = {} \n",
    "    self.head_notated_sort = {}\n",
    "    for network in tqdm(self.attentions_d, desc='annotation'):\n",
    "        self.head_sort[network] = sorted(\n",
    "            range(self.num_heads_d[network]), \n",
    "            key=lambda i: self.op(\n",
    "                self.corrs[network][other][i] for other in self.corrs[network]\n",
    "            ), \n",
    "            reverse=True,\n",
    "        )\n",
    "        self.head_notated_sort[network] = [\n",
    "            (\n",
    "                head,\n",
    "                {\n",
    "                    other : (\n",
    "                        self.corrs[network][other][head], \n",
    "                        self.pairs[network][other][head],\n",
    "                    ) \n",
    "                    for other in self.corrs[network]\n",
    "                }\n",
    "            ) \n",
    "            for head in self.head_sort[network]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary vals for arguments\n",
    "network = f1\n",
    "other_network = f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = self.device\n",
    "num_sentences = self.num_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set `total_corrs`\n",
    "total_corrs = np.zeros((num_sentences, self.num_heads_d[network],\n",
    "                        self.num_heads_d[other_network]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for idx, (attns, o_attns) loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop variables\n",
    "idx = 2\n",
    "attns = self.attentions_d[network][idx]\n",
    "o_attns = self.attentions_d[other_network][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = attns.to(device)\n",
    "t2 = o_attns.to(device)\n",
    "t11, t12, t13 = t1.size()\n",
    "t21, t22, t23 = t2.size()\n",
    "t1 = t1.reshape(t11, 1, t12, t13)\n",
    "t2 = t2.reshape(1, t21, t22, t23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `corr`\n",
    "nz = (t1!=0) & (t2!=0) # \"nonzero\"\n",
    "n = nz.sum(dim=-1).float() # n = length to use\n",
    "x1, x2 = t1.sum(dim=-1), t2.sum(dim=-1)\n",
    "x11, x12, x22 = (t1*t1).sum(dim=-1), (t1*t2).sum(dim=-1), (t2*t2).sum(dim=-1)\n",
    "num = x12-(x1*x2/n)\n",
    "denom = torch.sqrt((x11-(x1*x1/n)) * (x22-(x2*x2/n)))\n",
    "corr = num/denom\n",
    "corr[n < 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corrs[idx] = corr.sum(dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full loop\n",
    "for idx, (attns, o_attns) in enumerate(\n",
    "        zip(self.attentions_d[network],\n",
    "            self.attentions_d[other_network])):\n",
    "    t1 = attns.to(device)\n",
    "    t2 = o_attns.to(device)\n",
    "    t11, t12, t13 = t1.size()\n",
    "    t21, t22, t23 = t2.size()\n",
    "    t1 = t1.reshape(t11, 1, t12, t13)\n",
    "    t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "    # Set `corr`\n",
    "    nz = (t1!=0) & (t2!=0) # \"nonzero\"\n",
    "    n = nz.sum(dim=-1).float() # n = length to use\n",
    "    x1, x2 = t1.sum(dim=-1), t2.sum(dim=-1)\n",
    "    x11, x12, x22 = (t1*t1).sum(dim=-1), (t1*t2).sum(dim=-1), (t2*t2).sum(dim=-1)\n",
    "    num = x12-(x1*x2/n)\n",
    "    denom = torch.sqrt((x11-(x1*x1/n)) * (x22-(x2*x2/n)))\n",
    "    corr = num/denom\n",
    "\n",
    "    corr = corr.cpu().numpy()\n",
    "    corr[~np.isfinite(corr)] = 0\n",
    "    total_corrs[idx] = corr.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(self, network, other_network):\n",
    "    device = self.device\n",
    "    num_sentences = self.num_sentences\n",
    "\n",
    "    # set `total_corrs`\n",
    "    total_corrs = np.zeros((num_sentences, self.num_heads_d[network],\n",
    "                            self.num_heads_d[other_network]))\n",
    "    for idx, (attns, o_attns) in enumerate(\n",
    "            zip(self.attentions_d[network],\n",
    "                self.attentions_d[other_network])):\n",
    "        t1 = attns.to(device)\n",
    "        t2 = o_attns.to(device)\n",
    "        t11, t12, t13 = t1.size()\n",
    "        t21, t22, t23 = t2.size()\n",
    "        t1 = t1.reshape(t11, 1, t12, t13)\n",
    "        t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "        # Set `corr`\n",
    "        nz = (t1!=0) & (t2!=0) # \"nonzero\"\n",
    "        n = nz.sum(dim=-1).float() # n = length to use\n",
    "        x1, x2 = t1.sum(dim=-1), t2.sum(dim=-1)\n",
    "        x11, x12, x22 = (t1*t1).sum(dim=-1), (t1*t2).sum(dim=-1), (t2*t2).sum(dim=-1)\n",
    "        num = x12-(x1*x2/n)\n",
    "        denom = torch.sqrt((x11-(x1*x1/n)) * (x22-(x2*x2/n)))\n",
    "        corr = num/denom\n",
    "\n",
    "        corr = corr.cpu().numpy()\n",
    "        corr[~np.isfinite(corr)] = 0\n",
    "        total_corrs[idx] = corr.sum(axis=-1)\n",
    "\n",
    "    # set `correlation`\n",
    "    correlation = total_corrs.sum(axis=0)/self.num_words\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.correlation_matrix = lambda n, o_n: correlation_matrix(self, n, o_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "correlate: 100%|█████████████████████████████| 9/9 [00:00<00:00, 1016.45it/s]\n",
      "annotation: 100%|████████████████████████████| 3/3 [00:00<00:00, 8548.17it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_correlations(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': {'bar': 0.10310055208067562, 'baz': 0.12652370506940885},\n",
       " 'bar': {'foo': 0.10782335860322613, 'baz': 0.12433415669370297},\n",
       " 'baz': {'foo': 0.12067727221058454, 'bar': 0.11247482138416696}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
