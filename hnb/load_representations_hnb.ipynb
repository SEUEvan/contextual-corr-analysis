{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from os.path import basename, dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set arguments arbitrarily\n",
    "limit = 10000\n",
    "layerspec_l = [\n",
    "    \"full\", \n",
    "    -1, \n",
    "]\n",
    "first_half_only_l = [\n",
    "    False, \n",
    "    False,\n",
    "]\n",
    "second_half_only_l = [\n",
    "    False,\n",
    "    False\n",
    "]\n",
    "representation_fname_l = [\n",
    "    \"/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5\",\n",
    "    \"/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fname2mname(fname):\n",
    "    \"\"\"\n",
    "    \"filename to model name\". \n",
    "    \"\"\"\n",
    "    return basename(dirname(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons_d = {} \n",
    "representations_d = {} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for fname in ... loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop variables\n",
    "ix = 0\n",
    "layerspec = layerspec_l[ix]\n",
    "first_half_only = first_half_only_l[ix]\n",
    "second_half_only = second_half_only_l[ix]\n",
    "fname = representation_fname_l[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `activations_h5`, `sentence_d`, `indices`\n",
    "activations_h5 = h5py.File(fname, 'r')\n",
    "sentence_d = json.loads(activations_h5['sentence_to_index'][0])\n",
    "temp = {} # TO DO: Make this more elegant?\n",
    "for k, v in sentence_d.items():\n",
    "    temp[v] = k\n",
    "sentence_d = temp # {str ix, sentence}\n",
    "indices = list(sentence_d.keys())[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_layers`, `num_neurons`, `layers`\n",
    "s = activations_h5[indices[0]].shape\n",
    "num_layers = 1 if len(s)==2 else s[0]\n",
    "num_neurons = s[-1]\n",
    "if layerspec == \"all\":\n",
    "    layers = list(range(num_layers))\n",
    "elif layerspec == \"full\":\n",
    "    layers = [\"full\"]\n",
    "else:\n",
    "    layers = [layerspec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_neurons_d`, `representations_d`\n",
    "for layer in layers:\n",
    "    # Create `representations_l`\n",
    "    representations_l = []\n",
    "    for sentence_ix in indices: \n",
    "        # Set `dim`\n",
    "        dim = len(activations_h5[sentence_ix].shape)\n",
    "        if not (dim == 2 or dim == 3):\n",
    "            raise ValueError('Improper array dimension in file: ' +\n",
    "                             fname + \"\\nShape: \" +\n",
    "                             str(activations_h5[sentence_ix].shape))\n",
    "        \n",
    "        # Create `activations`\n",
    "        if layer == \"full\":\n",
    "            activations = torch.FloatTensor(activations_h5[sentence_ix])\n",
    "            if dim == 3:\n",
    "                activations = activations.permute(1, 0, 2)\n",
    "                nword, nlayer, nneuron = activations.size()\n",
    "                activations = activations.view(nword, -1)\n",
    "        else:\n",
    "            activations = torch.FloatTensor(activations_h5[sentence_ix][layer] if dim==3 \n",
    "                                                else activations_h5[sentence_ix])\n",
    "\n",
    "        # Create `representations`\n",
    "        representations = activations\n",
    "        if first_half_only: \n",
    "            representations = torch.chunk(representations, chunks=2,\n",
    "                                          dim=-1)[0]\n",
    "        elif second_half_only:\n",
    "            representations = torch.chunk(representations, chunks=2,\n",
    "                                          dim=-1)[1]\n",
    "\n",
    "        representations_l.append(representations)\n",
    "    \n",
    "    # update\n",
    "    model_name = \"{model}_{layer}\".format(model=fname2mname(fname), \n",
    "                                          layer=layer)\n",
    "    num_neurons_d[model_name] = representations_l[0].size()[-1]\n",
    "    representations_d[model_name] = torch.cat(representations_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:06, 57.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# full\n",
    "for loop_var in tqdm(zip(representation_fname_l, layerspec_l,\n",
    "                         first_half_only_l, second_half_only_l)):\n",
    "    fname, layerspec, first_half_only, second_half_only = loop_var\n",
    "\n",
    "    # Set `activations_h5`, `sentence_d`, `indices`\n",
    "    activations_h5 = h5py.File(fname, 'r')\n",
    "    sentence_d = json.loads(activations_h5['sentence_to_index'][0])\n",
    "    temp = {} # TO DO: Make this more elegant?\n",
    "    for k, v in sentence_d.items():\n",
    "        temp[v] = k\n",
    "    sentence_d = temp # {str ix, sentence}\n",
    "    indices = list(sentence_d.keys())[:limit]\n",
    "\n",
    "    # Set `num_layers`, `num_neurons`, `layers`\n",
    "    s = activations_h5[indices[0]].shape\n",
    "    num_layers = 1 if len(s)==2 else s[0]\n",
    "    num_neurons = s[-1]\n",
    "    if layerspec == \"all\":\n",
    "        layers = list(range(num_layers))\n",
    "    elif layerspec == \"full\":\n",
    "        layers = [\"full\"]\n",
    "    else:\n",
    "        layers = [layerspec]\n",
    "\n",
    "    # Set `num_neurons_d`, `representations_d`\n",
    "    for layer in layers:\n",
    "        # Create `representations_l`\n",
    "        representations_l = []\n",
    "        for sentence_ix in indices: \n",
    "            # Set `dim`\n",
    "            dim = len(activations_h5[sentence_ix].shape)\n",
    "            if not (dim == 2 or dim == 3):\n",
    "                raise ValueError('Improper array dimension in file: ' +\n",
    "                                 fname + \"\\nShape: \" +\n",
    "                                 str(activations_h5[sentence_ix].shape))\n",
    "\n",
    "            # Create `activations`\n",
    "            if layer == \"full\":\n",
    "                activations = torch.FloatTensor(activations_h5[sentence_ix])\n",
    "                if dim == 3:\n",
    "                    activations = activations.permute(1, 0, 2)\n",
    "                    nword = activations.size()[0]\n",
    "                    activations = activations.contiguous().view(nword, -1)\n",
    "            else:\n",
    "                activations = torch.FloatTensor(activations_h5[sentence_ix][layer] if dim==3 \n",
    "                                                    else activations_h5[sentence_ix])\n",
    "\n",
    "            # Create `representations`\n",
    "            representations = activations\n",
    "            if first_half_only: \n",
    "                representations = torch.chunk(representations, chunks=2,\n",
    "                                              dim=-1)[0]\n",
    "            elif second_half_only:\n",
    "                representations = torch.chunk(representations, chunks=2,\n",
    "                                              dim=-1)[1]\n",
    "\n",
    "            representations_l.append(representations)\n",
    "\n",
    "        # update\n",
    "        model_name = \"{model}_{layer}\".format(model=fname2mname(fname), \n",
    "                                              layer=layer)\n",
    "        num_neurons_d[model_name] = representations_l[0].size()[-1]\n",
    "        representations_d[model_name] = torch.cat(representations_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elmo_original_0': 1024,\n",
       " 'elmo_original_1': 1024,\n",
       " 'elmo_original_2': 1024,\n",
       " 'calypso_transformer_6_512_base_-1': 1024,\n",
       " 'elmo_original_full': 3072}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neurons_d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
