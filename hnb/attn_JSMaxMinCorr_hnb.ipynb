{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "from itertools import product as p\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from os.path import basename, dirname\n",
    "#import dask.array as da\n",
    "import pickle\n",
    "from var import fname2mname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvec(t):\n",
    "    return t/t.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "self = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_heads_d = {} # {fname, int}\n",
    "self.attentions_d = {} # {fname, tensor}\n",
    "f1, f2, f3 = \"foo\", \"bar\", \"baz\"\n",
    "attention_fname_l = [f1, f2, f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize `num_heads_d`, `attentions_d` with fake data\n",
    "n1, n2, n3 = 10, 12, 14\n",
    "wlen_l = [27, 5, 9, 6]\n",
    "\n",
    "self.num_heads_d[f1] = n1\n",
    "self.num_heads_d[f2] = n2\n",
    "self.num_heads_d[f3] = n3\n",
    "\n",
    "for fname in attention_fname_l:\n",
    "    attentions_l = [pvec(torch.abs(torch.randn(self.num_heads_d[fname], wlen, wlen)))\n",
    "                        for wlen in wlen_l]\n",
    "    self.attentions_d[fname] = attentions_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.device = torch.device('cpu')\n",
    "self.op = min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.num_sentences = len(wlen_l)\n",
    "self.num_words = sum(wlen_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(self):\n",
    "    # convenient variables\n",
    "    device = self.device\n",
    "    self.num_sentences = len(next(iter(self.attentions_d.values())))\n",
    "    self.num_words = sum(t.size()[-1] for t in next(iter(self.attentions_d.values())))\n",
    "\n",
    "    # Set `self.corrs` : {network: {other: [corr]}}\n",
    "    # Set `self.pairs` : {network: {other: [pair]}}\n",
    "    # pair is index of head in other network\n",
    "    # Set `self.similarities` : {network: {other: sim}}\n",
    "    self.corrs = {network: {} for network in self.attentions_d}\n",
    "    self.pairs = {network: {} for network in self.attentions_d}\n",
    "    self.similarities = {network: {} for network in self.attentions_d}\n",
    "    for network, other_network in tqdm(p(self.attentions_d,\n",
    "                                         self.attentions_d),\n",
    "                                         desc='correlate',\n",
    "                                         total=len(self.attentions_d)**2):\n",
    "        if network == other_network:\n",
    "            continue\n",
    "\n",
    "        if other_network in self.corrs[network]: \n",
    "            continue\n",
    "\n",
    "        correlation = self.correlation_matrix(network, other_network)\n",
    "\n",
    "        # Main update\n",
    "        self.corrs[network][other_network] = correlation.max(axis=1)\n",
    "        self.corrs[other_network][network] = correlation.max(axis=0)\n",
    "\n",
    "        self.similarities[network][other_network] = self.corrs[network][other_network].mean()\n",
    "        self.similarities[other_network][network] = self.corrs[other_network][network].mean()\n",
    "\n",
    "        self.pairs[network][other_network] = correlation.argmax(axis=1)\n",
    "        self.pairs[other_network][network] = correlation.argmax(axis=0)\n",
    "\n",
    "    # Set `self.head_sort` : {network, sorted_list}\n",
    "    # Set `self.head_notated_sort` : {network: [(head, {other: (corr, pair)})]}\n",
    "    self.head_sort = {} \n",
    "    self.head_notated_sort = {}\n",
    "    for network in tqdm(self.attentions_d, desc='annotation'):\n",
    "        self.head_sort[network] = sorted(\n",
    "            range(self.num_heads_d[network]), \n",
    "            key=lambda i: self.op(\n",
    "                self.corrs[network][other][i] for other in self.corrs[network]\n",
    "            ), \n",
    "            reverse=True,\n",
    "        )\n",
    "        self.head_notated_sort[network] = [\n",
    "            (\n",
    "                head,\n",
    "                {\n",
    "                    other : (\n",
    "                        self.corrs[network][other][head], \n",
    "                        self.pairs[network][other][head],\n",
    "                    ) \n",
    "                    for other in self.corrs[network]\n",
    "                }\n",
    "            ) \n",
    "            for head in self.head_sort[network]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary vals for arguments\n",
    "network = f1\n",
    "other_network = f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = self.device\n",
    "num_sentences = self.num_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dist = np.zeros((num_sentences, self.num_heads_d[network],\n",
    "                              self.num_heads_d[other_network]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for idx, (attns, o_attns) loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop variables\n",
    "idx = 2\n",
    "attns = self.attentions_d[network][idx]\n",
    "o_attns = self.attentions_d[other_network][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = attns.to(device)\n",
    "t2 = o_attns.to(device)\n",
    "t11, t12, t13 = t1.size()\n",
    "t21, t22, t23 = t2.size()\n",
    "t1 = t1.reshape(t11, 1, t12, t13)\n",
    "t2 = t2.reshape(1, t21, t22, t23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (t1+t2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl1 = torch.sum(t1*(torch.log(t1) - torch.log(m)), dim=-1) # D_KL(t1 || m)\n",
    "kl2 = torch.sum(t2*(torch.log(t2) - torch.log(m)), dim=-1) # D_KL(t2 || m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = (kl1 + kl2)/2 # avg seems to increase slightly with sent len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dist[idx] = js.sum(dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full loop\n",
    "for idx, (attns, o_attns) in enumerate(\n",
    "        zip(self.attentions_d[network],\n",
    "            self.attentions_d[other_network])):\n",
    "    t1 = attns.to(device)\n",
    "    t2 = o_attns.to(device)\n",
    "    t11, t12, t13 = t1.size()\n",
    "    t21, t22, t23 = t2.size()\n",
    "    t1 = t1.reshape(t11, 1, t12, t13)\n",
    "    t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "    m = (t1+t2)/2\n",
    "    kl1 = torch.sum(t1*(torch.log(t1) - torch.log(m)), dim=-1) # D_KL(t1 || m)\n",
    "    kl2 = torch.sum(t2*(torch.log(t2) - torch.log(m)), dim=-1) # D_KL(t2 || m)\n",
    "\n",
    "    js = (kl1 + kl2)/2 # avg seems to increase slightly with sent len\n",
    "    total_dist[idx] = js.sum(dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set `correlation`\n",
    "correlation = 1 - total_dist.sum(axis=0)/self.num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full function\n",
    "def correlation_matrix(self, network, other_network):\n",
    "    device = self.device\n",
    "    num_sentences = self.num_sentences\n",
    "\n",
    "    # set `total_corrs`\n",
    "    total_dist = np.zeros((num_sentences, self.num_heads_d[network],\n",
    "                                  self.num_heads_d[other_network]))\n",
    "    for idx, (attns, o_attns) in enumerate(\n",
    "            zip(self.attentions_d[network],\n",
    "                self.attentions_d[other_network])):\n",
    "        t1 = attns.to(device)\n",
    "        t2 = o_attns.to(device)\n",
    "        t11, t12, t13 = t1.size()\n",
    "        t21, t22, t23 = t2.size()\n",
    "        t1 = t1.reshape(t11, 1, t12, t13)\n",
    "        t2 = t2.reshape(1, t21, t22, t23)\n",
    "\n",
    "        m = (t1+t2)/2\n",
    "        kl1 = torch.sum(t1*(torch.log(t1) - torch.log(m)), dim=-1) # D_KL(t1 || m)\n",
    "        kl2 = torch.sum(t2*(torch.log(t2) - torch.log(m)), dim=-1) # D_KL(t2 || m)\n",
    "\n",
    "        js = (kl1 + kl2)/2 # avg seems to increase slightly with sent len\n",
    "        total_dist[idx] = js.sum(dim=-1).cpu().numpy()\n",
    "    \n",
    "    # set `correlation`\n",
    "    correlation = 1 - total_dist.sum(axis=0)/self.num_words\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.correlation_matrix = lambda n, o_n: correlation_matrix(self, n, o_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "correlate: 100%|██████████████████████████████| 9/9 [00:00<00:00, 918.68it/s]\n",
      "annotation: 100%|████████████████████████████| 3/3 [00:00<00:00, 8726.01it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_correlations(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': {'bar': 0.8752890853171653, 'baz': 0.8800703135576654},\n",
       " 'bar': {'foo': 0.8748066808420716, 'baz': 0.8757742386020667},\n",
       " 'baz': {'foo': 0.8784056040472535, 'bar': 0.8776379251190232}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
