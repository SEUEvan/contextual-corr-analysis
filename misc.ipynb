{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much space?\n",
    "All layers: 31.9 GB\n",
    "Just the top: 2.9GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['▁', '\"', '▁Mr', '.', '▁Allen', '▁objected', '▁to', '▁this', '▁analogy', '▁because', '▁it', '▁seems', '▁to', '▁', '\"', '▁assimilate', '▁the', '▁status', '▁of', '▁blacks', '▁to', '▁that', '▁of', '▁animals', '▁', '-', '-', '▁as', '▁a', '▁mere', '▁project', '▁of', '▁charity', '▁', ',', '▁of', '▁human', 'e', 'ness', '▁', '.', '▁', '”']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9601"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in l if s.find(chr(9601))>=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sent = 131611\n",
    "bytes_per_num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `n_layer_d`, `n_neuron_d`, `h5_d`\n",
    "network_l = [\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5',  \n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5',   \n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5',\n",
    "]\n",
    "\n",
    "n_layer_d = {}\n",
    "n_neuron_d = {}\n",
    "h5_d = {}\n",
    "for network in network_l:\n",
    "    h5_d[network] = h5py.File(network)\n",
    "    n_layer_d[network] = h5_d[network]['0'].shape[0]\n",
    "    n_neuron_d[network] = h5_d[network]['0'].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 /data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5\n"
     ]
    }
   ],
   "source": [
    "# find first sentence with diff tokenization\n",
    "for i in range(5512):\n",
    "    bert = network_l[0]\n",
    "    correct_length = h5_d[bert][str(i)].shape[1]\n",
    "    \n",
    "    for network in network_l:\n",
    "        l = h5_d[network][str(i)].shape[1]\n",
    "        if l > correct_length+1:\n",
    "            print(i, network)\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of different tokenizations\n",
    "count = 0\n",
    "for i in range(5512):\n",
    "    bert = network_l[0]\n",
    "    correct_length = h5_d[bert][str(i)].shape[1]\n",
    "    \n",
    "    for network in network_l:\n",
    "        l = h5_d[network][str(i)].shape[1]\n",
    "        if l > correct_length:\n",
    "            count += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4039"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5 (25, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5 (13, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5 (13, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5 (3, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5 (7, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5 (5, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5 (24, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5 (12, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5 (24, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5 (12, 38, 2048)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5 (12, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n"
     ]
    }
   ],
   "source": [
    "for network in network_l:\n",
    "    print(network, h5_d[network]['1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = network_l[0] # bert large\n",
    "net2 = network_l[8] # xlm enro\n",
    "\n",
    "json1 = json.loads(h5_d[net1]['sentence_to_index'][0])\n",
    "json2 = json.loads(h5_d[net2]['sentence_to_index'][0])\n",
    "\n",
    "json1 == json2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5': 25,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5': 13,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5': 13,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5': 3,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5': 7,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5': 5,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5': 24,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5': 12,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5': 24,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5': 12,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5': 12,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layer_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5': 2048,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5': 1024}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neuron_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96764618752"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for n_layer, n_neuron in zip(n_layer_d.values(), n_neuron_d.values()):\n",
    "    total += n_layer * n_neuron * n_sent * bytes_per_num\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8625258496"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just the top\n",
    "total = 0\n",
    "for n_layer, n_neuron in zip(n_layer_d.values(), n_neuron_d.values()):\n",
    "    total += n_neuron * n_sent * bytes_per_num\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the size of the loop\n",
    "sum(n_layer_d.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are the tests successful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_l = [\n",
    "    \"maxcorr\",\n",
    "    \"mincorr\",\n",
    "    \"maxlinreg\", \n",
    "    \"minlinreg\",\n",
    "    \"cca\",\n",
    "    \"lincka\",\n",
    "    # \"rbfcka\",\n",
    "]\n",
    "\n",
    "fname_d = {method: \"/data/sls/temp/johnmwu/contextual-corr-analysis/results_test_{0}\".format(method) \n",
    "           for method in method_l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "maxcorr\n",
      "dict_keys(['corrs', 'pairs', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "mincorr\n",
      "dict_keys(['corrs', 'pairs', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "maxlinreg\n",
      "dict_keys(['pred_power', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "minlinreg\n",
      "dict_keys(['pred_power', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "cca\n",
      "dict_keys(['corrs', 'sv_similarities', 'pw_alignments', 'pw_corrs', 'pw_similarities'])\n",
      "\n",
      "\n",
      "lincka\n",
      "dict_keys(['similarities'])\n"
     ]
    }
   ],
   "source": [
    "for method in method_l:\n",
    "    fname = fname_d[method]\n",
    "    f = open(fname, \"rb\")\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "    print(\"\\n\\n\" + method)\n",
    "    print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elmo_original_0': {'elmo_original_1': array([0.2644712 , 0.24154745, 0.3417127 , ..., 0.14911196, 0.3287669 ,\n",
       "         0.1628318 ], dtype=float32),\n",
       "  'elmo_original_2': array([0.2790686 , 0.17504421, 0.2784313 , ..., 0.14538047, 0.22215934,\n",
       "         0.15905769], dtype=float32)},\n",
       " 'elmo_original_1': {'elmo_original_0': array([0.29818842, 0.19084944, 0.17174841, ..., 0.17371958, 0.151198  ,\n",
       "         0.14904524], dtype=float32),\n",
       "  'elmo_original_2': array([0.6606671 , 0.6367155 , 0.54827076, ..., 0.7002142 , 0.6624288 ,\n",
       "         0.6925493 ], dtype=float32)},\n",
       " 'elmo_original_2': {'elmo_original_0': array([0.16851643, 0.12632947, 0.22938968, ..., 0.19309205, 0.13923243,\n",
       "         0.17923273], dtype=float32),\n",
       "  'elmo_original_1': array([0.6606671 , 0.6367155 , 0.54827076, ..., 0.7002142 , 0.6624288 ,\n",
       "         0.6925493 ], dtype=float32)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(fname_d[\"maxcorr\"], 'rb')\n",
    "data = pickle.load(f)\n",
    "data['corrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do the attn files look like?\n",
    "- They're structured the same way as the activations files\n",
    "- Each tensor is 4D, with axes (num_layers, num_heads, next_layer_ix, prev_layer_ix)\n",
    "- The values in the tensors are the values in\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(Q^TV)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param\n",
    "fname = \"/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev_attn.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(fname, 'r')\n",
    "sentence_d = json.loads(h5['sentence_to_index'][0])\n",
    "temp = {} # TO DO: Make this more elegant?\n",
    "for k, v in sentence_d.items():\n",
    "    temp[v] = k\n",
    "sentence_d = temp # {str ix, sentence}\n",
    "indices = list(sentence_d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence length: 8\n",
      "Shape: (12, 12, 8, 8)\n",
      "\n",
      "Sentence length: 33\n",
      "Shape: (12, 12, 33, 33)\n",
      "\n",
      "Sentence length: 28\n",
      "Shape: (12, 12, 28, 28)\n",
      "\n",
      "Sentence length: 21\n",
      "Shape: (12, 12, 21, 21)\n",
      "\n",
      "Sentence length: 19\n",
      "Shape: (12, 12, 19, 19)\n",
      "\n",
      "Sentence length: 7\n",
      "Shape: (12, 12, 7, 7)\n",
      "\n",
      "Sentence length: 24\n",
      "Shape: (12, 12, 24, 24)\n",
      "\n",
      "Sentence length: 22\n",
      "Shape: (12, 12, 22, 22)\n",
      "\n",
      "Sentence length: 27\n",
      "Shape: (12, 12, 27, 27)\n",
      "\n",
      "Sentence length: 23\n",
      "Shape: (12, 12, 23, 23)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Order of axes\n",
    "for i in range(10):\n",
    "    ix = str(i)\n",
    "    sent = sentence_d[ix]\n",
    "    attn = h5[ix]\n",
    "    \n",
    "    print(\"Sentence length: {0}\".format(len(sent.split())))\n",
    "    print(\"Shape: {0}\".format(attn.shape))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.0000001 , 1.        ,\n",
       "       0.99999994, 1.        , 0.9999999 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What exactly is contained? Also, order of last two axes\n",
    "attn_ar = np.array(h5['0'])\n",
    "a = attn_ar[0, 0, :, :]\n",
    "a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xlnet wanted sizes are zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev_mnli.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(fname, 'r')\n",
    "sentence_d = json.loads(h5['sentence_to_index'][0])\n",
    "temp = {} # TO DO: Make this more elegant?\n",
    "for k, v in sentence_d.items():\n",
    "    temp[v] = k\n",
    "sentence_d = temp # {str ix, sentence}\n",
    "indices = list(sentence_d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2408489 , -0.800417  , -0.05489704, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004171 , -0.05489708, -0.20166902, -0.53048587],\n",
       "       [-0.24084893, -0.8004171 , -0.05489707, -0.201669  , -0.53048587],\n",
       "       [-0.24084893, -0.8004171 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.2408489 , -0.8004171 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.2408489 , -0.8004171 , -0.05489706, -0.20166911, -0.53048575],\n",
       "       [-0.2408489 , -0.800417  , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084884, -0.8004171 , -0.05489708, -0.2016691 , -0.53048575]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5['0'][11][:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24084891, -0.8004172 , -0.05489706, -0.20166914, -0.53048587],\n",
       "       [-0.2408489 , -0.8004173 , -0.05489706, -0.20166911, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489708, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004173 , -0.05489706, -0.20166919, -0.53048587],\n",
       "       [-0.24084891, -0.8004172 , -0.05489707, -0.20166917, -0.5304858 ],\n",
       "       [-0.2408489 , -0.8004172 , -0.05489707, -0.2016692 , -0.53048587],\n",
       "       [-0.24084891, -0.8004173 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489706, -0.20166913, -0.5304858 ],\n",
       "       [-0.24084891, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.054897  , -0.20166913, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.2408489 , -0.8004172 , -0.05489708, -0.20166911, -0.53048587],\n",
       "       [-0.24084891, -0.8004171 , -0.05489706, -0.20166916, -0.5304858 ],\n",
       "       [-0.2408489 , -0.8004172 , -0.054897  , -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489704, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004172 , -0.05489704, -0.20166913, -0.5304858 ],\n",
       "       [-0.2408489 , -0.8004172 , -0.05489706, -0.20166923, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.054897  , -0.20166916, -0.53048587],\n",
       "       [-0.24084894, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004172 , -0.05489707, -0.20166914, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489707, -0.2016691 , -0.53048575],\n",
       "       [-0.24084899, -0.8004171 , -0.05489706, -0.2016692 , -0.53048587],\n",
       "       [-0.24084894, -0.800417  , -0.05489706, -0.20166913, -0.5304858 ],\n",
       "       [-0.24084899, -0.8004172 , -0.05489707, -0.20166923, -0.53048587],\n",
       "       [-0.24084894, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489707, -0.20166916, -0.53048587],\n",
       "       [-0.24084891, -0.8004171 , -0.05489708, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489704, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489704, -0.20166911, -0.53048587],\n",
       "       [-0.24084894, -0.8004171 , -0.05489706, -0.20166916, -0.5304858 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5['1'][11][:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"1\": shape (12, 33, 768), type \"<f4\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5['1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
