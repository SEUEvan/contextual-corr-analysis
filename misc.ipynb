{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much space?\n",
    "All layers: 31.9 GB\n",
    "Just the top: 2.9GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['▁', '\"', '▁Mr', '.', '▁Allen', '▁objected', '▁to', '▁this', '▁analogy', '▁because', '▁it', '▁seems', '▁to', '▁', '\"', '▁assimilate', '▁the', '▁status', '▁of', '▁blacks', '▁to', '▁that', '▁of', '▁animals', '▁', '-', '-', '▁as', '▁a', '▁mere', '▁project', '▁of', '▁charity', '▁', ',', '▁of', '▁human', 'e', 'ness', '▁', '.', '▁', '”']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9601"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in l if s.find(chr(9601))>=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sent = 131611\n",
    "bytes_per_num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `n_layer_d`, `n_neuron_d`, `h5_d`\n",
    "network_l = [\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5',  \n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5',   \n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5',\n",
    "    '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5',\n",
    "]\n",
    "\n",
    "n_layer_d = {}\n",
    "n_neuron_d = {}\n",
    "h5_d = {}\n",
    "for network in network_l:\n",
    "    h5_d[network] = h5py.File(network)\n",
    "    n_layer_d[network] = h5_d[network]['0'].shape[0]\n",
    "    n_neuron_d[network] = h5_d[network]['0'].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 /data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5\n"
     ]
    }
   ],
   "source": [
    "# find first sentence with diff tokenization\n",
    "for i in range(5512):\n",
    "    bert = network_l[0]\n",
    "    correct_length = h5_d[bert][str(i)].shape[1]\n",
    "    \n",
    "    for network in network_l:\n",
    "        l = h5_d[network][str(i)].shape[1]\n",
    "        if l > correct_length+1:\n",
    "            print(i, network)\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of different tokenizations\n",
    "count = 0\n",
    "for i in range(5512):\n",
    "    bert = network_l[0]\n",
    "    correct_length = h5_d[bert][str(i)].shape[1]\n",
    "    \n",
    "    for network in network_l:\n",
    "        l = h5_d[network][str(i)].shape[1]\n",
    "        if l > correct_length:\n",
    "            count += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4039"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5 (25, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5 (13, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5 (13, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5 (3, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5 (7, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5 (5, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5 (24, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5 (12, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5 (24, 33, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5 (12, 38, 2048)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5 (12, 33, 768)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n",
      "/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5 (6, 36, 1024)\n"
     ]
    }
   ],
   "source": [
    "for network in network_l:\n",
    "    print(network, h5_d[network]['1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = network_l[0] # bert large\n",
    "net2 = network_l[8] # xlm enro\n",
    "\n",
    "json1 = json.loads(h5_d[net1]['sentence_to_index'][0])\n",
    "json2 = json.loads(h5_d[net2]['sentence_to_index'][0])\n",
    "\n",
    "json1 == json2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5': 25,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5': 13,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5': 13,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5': 3,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5': 7,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5': 5,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5': 24,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5': 12,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5': 24,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5': 12,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5': 12,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5': 6,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layer_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_large_cased/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/openai_transformer/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_original/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/calypso_transformer_6_512_base/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/elmo_4x4096_512/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_large_cased/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_small/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enro-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-enfr-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/gpt2_medium/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-en-2048/ptb_pos_dev.hdf5': 2048,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-ende-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev.hdf5': 768,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-mlm-ende-1024/ptb_pos_dev.hdf5': 1024,\n",
       " '/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlm-clm-enfr-1024/ptb_pos_dev.hdf5': 1024}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neuron_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96764618752"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for n_layer, n_neuron in zip(n_layer_d.values(), n_neuron_d.values()):\n",
    "    total += n_layer * n_neuron * n_sent * bytes_per_num\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8625258496"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just the top\n",
    "total = 0\n",
    "for n_layer, n_neuron in zip(n_layer_d.values(), n_neuron_d.values()):\n",
    "    total += n_neuron * n_sent * bytes_per_num\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the size of the loop\n",
    "sum(n_layer_d.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are the tests successful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_l = [\n",
    "    \"maxcorr\",\n",
    "    \"mincorr\",\n",
    "    \"maxlinreg\", \n",
    "    \"minlinreg\",\n",
    "    \"cca\",\n",
    "    \"lincka\",\n",
    "    # \"rbfcka\",\n",
    "]\n",
    "\n",
    "fname_d = {method: \"/data/sls/temp/johnmwu/contextual-corr-analysis/results_test_{0}\".format(method) \n",
    "           for method in method_l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "maxcorr\n",
      "dict_keys(['corrs', 'pairs', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "mincorr\n",
      "dict_keys(['corrs', 'pairs', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "maxlinreg\n",
      "dict_keys(['pred_power', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "minlinreg\n",
      "dict_keys(['pred_power', 'similarities', 'neuron_sort', 'neuron_notated_sort'])\n",
      "\n",
      "\n",
      "cca\n",
      "dict_keys(['corrs', 'sv_similarities', 'pw_alignments', 'pw_corrs', 'pw_similarities'])\n",
      "\n",
      "\n",
      "lincka\n",
      "dict_keys(['similarities'])\n"
     ]
    }
   ],
   "source": [
    "for method in method_l:\n",
    "    fname = fname_d[method]\n",
    "    f = open(fname, \"rb\")\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "    print(\"\\n\\n\" + method)\n",
    "    print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elmo_original_0': {'elmo_original_1': array([0.2644712 , 0.24154745, 0.3417127 , ..., 0.14911196, 0.3287669 ,\n",
       "         0.1628318 ], dtype=float32),\n",
       "  'elmo_original_2': array([0.2790686 , 0.17504421, 0.2784313 , ..., 0.14538047, 0.22215934,\n",
       "         0.15905769], dtype=float32)},\n",
       " 'elmo_original_1': {'elmo_original_0': array([0.29818842, 0.19084944, 0.17174841, ..., 0.17371958, 0.151198  ,\n",
       "         0.14904524], dtype=float32),\n",
       "  'elmo_original_2': array([0.6606671 , 0.6367155 , 0.54827076, ..., 0.7002142 , 0.6624288 ,\n",
       "         0.6925493 ], dtype=float32)},\n",
       " 'elmo_original_2': {'elmo_original_0': array([0.16851643, 0.12632947, 0.22938968, ..., 0.19309205, 0.13923243,\n",
       "         0.17923273], dtype=float32),\n",
       "  'elmo_original_1': array([0.6606671 , 0.6367155 , 0.54827076, ..., 0.7002142 , 0.6624288 ,\n",
       "         0.6925493 ], dtype=float32)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(fname_d[\"maxcorr\"], 'rb')\n",
    "data = pickle.load(f)\n",
    "data['corrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do the attn files look like?\n",
    "- They're structured the same way as the activations files\n",
    "- Each tensor is 4D, with axes (num_layers, num_heads, next_layer_ix, prev_layer_ix)\n",
    "- The values in the tensors are the values in\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(Q^TV)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param\n",
    "fname = \"/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev_attn.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(fname, 'r')\n",
    "sentence_d = json.loads(h5['sentence_to_index'][0])\n",
    "temp = {} # TO DO: Make this more elegant?\n",
    "for k, v in sentence_d.items():\n",
    "    temp[v] = k\n",
    "sentence_d = temp # {str ix, sentence}\n",
    "indices = list(sentence_d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence length: 8\n",
      "Shape: (12, 12, 8, 8)\n",
      "\n",
      "Sentence length: 33\n",
      "Shape: (12, 12, 33, 33)\n",
      "\n",
      "Sentence length: 28\n",
      "Shape: (12, 12, 28, 28)\n",
      "\n",
      "Sentence length: 21\n",
      "Shape: (12, 12, 21, 21)\n",
      "\n",
      "Sentence length: 19\n",
      "Shape: (12, 12, 19, 19)\n",
      "\n",
      "Sentence length: 7\n",
      "Shape: (12, 12, 7, 7)\n",
      "\n",
      "Sentence length: 24\n",
      "Shape: (12, 12, 24, 24)\n",
      "\n",
      "Sentence length: 22\n",
      "Shape: (12, 12, 22, 22)\n",
      "\n",
      "Sentence length: 27\n",
      "Shape: (12, 12, 27, 27)\n",
      "\n",
      "Sentence length: 23\n",
      "Shape: (12, 12, 23, 23)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Order of axes\n",
    "for i in range(10):\n",
    "    ix = str(i)\n",
    "    sent = sentence_d[ix]\n",
    "    attn = h5[ix]\n",
    "    \n",
    "    print(\"Sentence length: {0}\".format(len(sent.split())))\n",
    "    print(\"Shape: {0}\".format(attn.shape))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99999994], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What exactly is contained? Also, order of last two axes\n",
    "attn_ar = np.array(h5['3405'])\n",
    "a = attn_ar[0, 0, :, :]\n",
    "a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90824974 0.0917503 ]\n",
      " [0.9087661  0.09123389]]\n",
      "[[0.9450725  0.05492758]\n",
      " [0.98557544 0.01442447]]\n",
      "[[0.93533957 0.06466043]\n",
      " [0.9872321  0.0127679 ]]\n",
      "[[0.7961024  0.20389754]\n",
      " [0.93405366 0.06594636]]\n",
      "[[0.8841361  0.11586393]\n",
      " [0.8325231  0.16747688]]\n",
      "[[0.9540099  0.04599005]\n",
      " [0.8944529  0.105547  ]]\n",
      "[[0.95842683 0.04157317]\n",
      " [0.92747676 0.07252326]]\n",
      "[[0.9772744  0.02272559]\n",
      " [0.23067053 0.7693294 ]]\n",
      "[[0.8956895  0.10431045]\n",
      " [0.98439395 0.01560605]]\n",
      "[[0.62169164 0.37830836]\n",
      " [0.5389814  0.46101865]]\n",
      "[[0.8585013  0.14149868]\n",
      " [0.69356483 0.3064352 ]]\n",
      "[[9.9905354e-01 9.4647484e-04]\n",
      " [9.8925859e-01 1.0741444e-02]]\n"
     ]
    }
   ],
   "source": [
    "for a in np.array(h5['3496'])[3]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56150335, 0.43849668],\n",
       "       [0.64035594, 0.35964406]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xlnet wanted sizes are zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/xlnet_base_cased/ptb_pos_dev_mnli.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(fname, 'r')\n",
    "sentence_d = json.loads(h5['sentence_to_index'][0])\n",
    "temp = {} # TO DO: Make this more elegant?\n",
    "for k, v in sentence_d.items():\n",
    "    temp[v] = k\n",
    "sentence_d = temp # {str ix, sentence}\n",
    "indices = list(sentence_d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2408489 , -0.800417  , -0.05489704, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004171 , -0.05489708, -0.20166902, -0.53048587],\n",
       "       [-0.24084893, -0.8004171 , -0.05489707, -0.201669  , -0.53048587],\n",
       "       [-0.24084893, -0.8004171 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.2408489 , -0.8004171 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.2408489 , -0.8004171 , -0.05489706, -0.20166911, -0.53048575],\n",
       "       [-0.2408489 , -0.800417  , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084884, -0.8004171 , -0.05489708, -0.2016691 , -0.53048575]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5['0'][11][:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24084891, -0.8004172 , -0.05489706, -0.20166914, -0.53048587],\n",
       "       [-0.2408489 , -0.8004173 , -0.05489706, -0.20166911, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489708, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004173 , -0.05489706, -0.20166919, -0.53048587],\n",
       "       [-0.24084891, -0.8004172 , -0.05489707, -0.20166917, -0.5304858 ],\n",
       "       [-0.2408489 , -0.8004172 , -0.05489707, -0.2016692 , -0.53048587],\n",
       "       [-0.24084891, -0.8004173 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489706, -0.20166913, -0.5304858 ],\n",
       "       [-0.24084891, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.054897  , -0.20166913, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.2408489 , -0.8004172 , -0.05489708, -0.20166911, -0.53048587],\n",
       "       [-0.24084891, -0.8004171 , -0.05489706, -0.20166916, -0.5304858 ],\n",
       "       [-0.2408489 , -0.8004172 , -0.054897  , -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489704, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004172 , -0.05489704, -0.20166913, -0.5304858 ],\n",
       "       [-0.2408489 , -0.8004172 , -0.05489706, -0.20166923, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.054897  , -0.20166916, -0.53048587],\n",
       "       [-0.24084894, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004172 , -0.05489707, -0.20166914, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489707, -0.2016691 , -0.53048575],\n",
       "       [-0.24084899, -0.8004171 , -0.05489706, -0.2016692 , -0.53048587],\n",
       "       [-0.24084894, -0.800417  , -0.05489706, -0.20166913, -0.5304858 ],\n",
       "       [-0.24084899, -0.8004172 , -0.05489707, -0.20166923, -0.53048587],\n",
       "       [-0.24084894, -0.8004172 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489707, -0.20166916, -0.53048587],\n",
       "       [-0.24084891, -0.8004171 , -0.05489708, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489704, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489706, -0.2016691 , -0.53048587],\n",
       "       [-0.24084896, -0.8004171 , -0.05489706, -0.20166916, -0.53048587],\n",
       "       [-0.24084893, -0.8004172 , -0.05489704, -0.20166911, -0.53048587],\n",
       "       [-0.24084894, -0.8004171 , -0.05489706, -0.20166916, -0.5304858 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5['1'][11][:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"1\": shape (12, 33, 768), type \"<f4\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is PearsonMaxMinCorr2 getting infs and NaNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param\n",
    "fname = \"/data/sls/temp/belinkov/contextual-corr-analysis/contextualizers/bert_base_cased/ptb_pos_dev_attn.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an offending pair, according to the output\n",
    "idx = '3405'\n",
    "l1, l2 = 3, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(fname, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.FloatTensor(h5[idx][l1])\n",
    "t2 = torch.FloatTensor(h5[idx][l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t11, t12, t13 = t1.size()\n",
    "t21, t22, t23 = t2.size()\n",
    "t1 = t1.reshape(t11, 1, t12, t13)\n",
    "t2 = t2.reshape(1, t21, t22, t23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = (t1!=0) & (t2!=0) # \"nonzero\"\n",
    "n = nz.sum(dim=-1).float() # n = length to use\n",
    "x1, x2 = t1.sum(dim=-1), t2.sum(dim=-1)\n",
    "x11, x12, x22 = (t1*t1).sum(dim=-1), (t1*t2).sum(dim=-1), (t2*t2).sum(dim=-1)\n",
    "num = x12-(x1*x2/n)\n",
    "denom = torch.sqrt((x11-(x1*x1/n)) * (x22-(x2*x2/n)))\n",
    "corr = num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697],\n",
       "         [0.3480, 0.3697]],\n",
       "\n",
       "        [[0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898],\n",
       "         [0.4282, 0.4898]],\n",
       "\n",
       "        [[0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844],\n",
       "         [0.2975, 0.3844]],\n",
       "\n",
       "        [[0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378],\n",
       "         [0.2391, 0.2378]],\n",
       "\n",
       "        [[0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354],\n",
       "         [0.0786, 0.0354]],\n",
       "\n",
       "        [[0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028],\n",
       "         [0.1958, 0.2028]],\n",
       "\n",
       "        [[0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866],\n",
       "         [0.3021, 0.2866]],\n",
       "\n",
       "        [[0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567],\n",
       "         [0.4601, 0.1567]],\n",
       "\n",
       "        [[0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199],\n",
       "         [0.1480, 0.3199]],\n",
       "\n",
       "        [[0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310],\n",
       "         [0.3122, 0.0310]],\n",
       "\n",
       "        [[0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829],\n",
       "         [0.2575, 0.1829]],\n",
       "\n",
       "        [[0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000],\n",
       "         [0.4216, 0.0000]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x11-(x1*x1/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf],\n",
       "         [ 1.0000,    -inf]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(1)/torch.tensor(0) # this kills the kernel.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([inf])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([1]) / torch.FloatTensor([0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jmw0]",
   "language": "python",
   "name": "conda-env-jmw0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
