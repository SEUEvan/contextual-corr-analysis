{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- the rand networks' layers look the same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import basename, dirname\n",
    "import torch\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from ipywidgets import FloatSlider, interactive\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from var import fname2mname, network2pair, network_sort_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in them all made my machine run out of memory\n",
    "method_l = [\n",
    "    \"maxcorr\", \n",
    "#     \"mincorr\", \n",
    "#     \"maxlinreg\", \n",
    "#     \"minlinreg\", \n",
    "    \"cca\", \n",
    "    \"lincka\", \n",
    "    # \"rbfcka\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `res_d`, `network_l`, `num_neurons_d`\n",
    "base = \"/data/sls/temp/johnmwu/contextual-corr-analysis/results15_\"\n",
    "res_fname = {method : base + method for method in \n",
    "                method_l}\n",
    "\n",
    "res_d = {}\n",
    "for method in method_l:\n",
    "    with open(res_fname[method], 'rb') as f:\n",
    "        res_d[method] = pickle.load(f)\n",
    "\n",
    "network_l = [network for network in res_d[\"maxcorr\"][\"corrs\"]]\n",
    "network_l = sorted(network_l, key=network_sort_key)\n",
    "\n",
    "num_neurons_d = {}\n",
    "for network in network_l:\n",
    "    num_neurons_d[network] = len(next(iter(res_d[\"maxcorr\"][\"corrs\"][network].values()))) # god this is a hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxCorr, MinCorr, MaxLinReg, MinLinReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rk_methods = {\"maxcorr\", \"mincorr\", \"maxlinreg\", \"minlinreg\"}\n",
    "rk_methods = {\"maxcorr\"} #, \"mincorr\", \"maxlinreg\", \"minlinreg\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_sorts = {network: {} for network in network_l}\n",
    "for network in network_l:\n",
    "    for method in rk_methods:\n",
    "        neuron_sorts[network][method] = res_d[method][\"neuron_sort\"][network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `rk_ar_d`, `rk_df_d`, `spearman_d`\n",
    "rk_ar_d = {}\n",
    "rk_df_d = {}\n",
    "spearman_d = {}\n",
    "for network in network_l:\n",
    "    # rk_ar[method_ix, neuron] = rank\n",
    "    # need to invert the permutation\n",
    "    rk_ar = np.stack([\n",
    "            [neuron_sorts[network][method].index(neuron) for neuron in range(len(neuron_sorts[network][method]))]\n",
    "                      for method in rk_methods\n",
    "    ]).T\n",
    "    rk_df = pd.DataFrame(rk_ar, columns=list(rk_methods))\n",
    "    \n",
    "    rk_ar_d[network] = rk_ar\n",
    "    rk_df_d[network] = rk_df\n",
    "    spearman_d[network] = rk_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in network_l:\n",
    "    print(network)\n",
    "    # print(rk_df_d[network])\n",
    "    print(spearman_d[network])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in network_l:\n",
    "    print(\"\\n\\n\" + network + \":\")\n",
    "    for method in rk_methods:\n",
    "        print(\"\\n\" + method)\n",
    "        if method == \"maxlinreg\" or method == \"minlinreg\": \n",
    "            corr_df = pd.DataFrame(res_d[method]['pred_power'][network])\n",
    "        else:\n",
    "            corr_df = pd.DataFrame(res_d[method]['corrs'][network])\n",
    "        \n",
    "        print(\"\\nmaxcounts\")\n",
    "        print(corr_df.idxmax(axis=1).value_counts())\n",
    "        \n",
    "        print(\"\\nmincounts\")\n",
    "        print(corr_df.idxmin(axis=1).value_counts())\n",
    "        \n",
    "        print(\"\\ncorr_df_pctl\")\n",
    "        corr_df_pctl = pd.DataFrame()\n",
    "        corr_df_pctl[\"max\"] = corr_df.max(axis=1)\n",
    "        corr_df_pctl[\"min\"] = corr_df.min(axis=1)\n",
    "        corr_df_pctl[\"med\"] = corr_df.median(axis=1)\n",
    "        print(corr_df_pctl.rank().corr()) # spearman\n",
    "        \n",
    "#         corr_df.plot()\n",
    "#         plt.xlabel(\"neuron (sorted order)\")\n",
    "#         plt.ylabel(\"correlation\")\n",
    "#         plt.show()\n",
    "        \n",
    "#         plt.hist(corr_ar.ravel(), bins=100)\n",
    "#         plt.xlabel(\"correlation\")\n",
    "#         plt.ylabel(\"count\")\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinCKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lincka_df = pd.DataFrame(res_d['lincka']['similarities'])\n",
    "lincka_df = lincka_df.reindex(network_l)\n",
    "lincka_df = lincka_df.reindex(network_l, axis=1)\n",
    "#lincka_df = lincka_df.reindex(lincka_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lincka_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = \"elmo_original_0\"\n",
    "# lincka_df.sort_values(by=network)[network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBFCKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbfcka_d = torch.load(res_fname[\"rbfcka\"])\n",
    "# rbfcka_df = pd.DataFrame(rbfcka_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbfcka_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = \"bert_large_cased_0\"\n",
    "# rbfcka_df.sort_values(by=network)[network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_corrs = res_d['cca']['corrs']\n",
    "sv_similarities = res_d['cca']['sv_similarities']\n",
    "pw_similarities = res_d['cca']['pw_similarities']\n",
    "pw_corrs = res_d['cca']['pw_corrs']\n",
    "pw_alignments = res_d['cca']['pw_alignments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_sim_df = pd.DataFrame(sv_similarities)\n",
    "sv_sim_df = sv_sim_df.reindex(network_l)\n",
    "sv_sim_df = sv_sim_df.reindex(network_l, axis=1)\n",
    "# sv_sim_df = sv_sim_df.reindex(sv_sim_df.columns)\n",
    "\n",
    "pw_sim_df = pd.DataFrame(pw_similarities)\n",
    "pw_sim_df = pw_sim_df.reindex(network_l)\n",
    "pw_sim_df = pw_sim_df.reindex(network_l, axis=1)\n",
    "# pw_sim_df = pw_sim_df.reindex(pw_sim_df.columns)\n",
    "\n",
    "sv_corrs_df = pd.DataFrame(sv_corrs)\n",
    "sv_corrs_df = sv_corrs_df.reindex(network_l)\n",
    "sv_corrs_df = sv_corrs_df.reindex(network_l, axis=1)\n",
    "# sv_corrs_df = sv_corrs_df.reindex(sv_corrs_df.columns)\n",
    "\n",
    "pw_corrs_df = pd.DataFrame(pw_corrs)\n",
    "pw_corrs_df = pw_corrs_df.reindex(network_l)\n",
    "pw_corrs_df = pw_corrs_df.reindex(network_l, axis=1)\n",
    "# pw_corrs_df = pw_corrs_df.reindex(pw_corrs_df.columns)\n",
    "\n",
    "pw_alignments_df = pd.DataFrame(pw_alignments)\n",
    "pw_alignments_df = pw_alignments_df.reindex(network_l)\n",
    "pw_alignments_df = pw_alignments_df.reindex(network_l, axis=1)\n",
    "# pw_alignments_df = pw_alignments_df.reindex(pw_alignments_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corrs_df = sv_corrs_df.applymap(lambda t: float('nan') if type(t) is float else t.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = \"elmo_original_0\"\n",
    "# sv_sim_df.sort_values(by=network)[network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PWCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = \"elmo_original_0\"\n",
    "# pw_sim_df.sort_values(by=network)[network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lincka\n",
    "#short_labels = [label.split('-')[0] + ' ' + 'rand' if 'rand' in label else '' + ' ' + label.split('_')[-1] for label in network_l]\n",
    "#g = sns.heatmap(lincka_df.fillna(1), vmin=0, vmax=1, xticklabels=short_labels, yticklabels=short_labels)\n",
    "g = sns.heatmap(lincka_df.fillna(1), vmin=0, vmax=1)\n",
    "g.get_figure().savefig('random-lincka-heatmap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrs_update(fl, corr_df, fname_prefix, weights_df=None):\n",
    "    fname = \"{0}{1:.2f}.png\".format(fname_prefix, fl)\n",
    "    try:\n",
    "        im = plt.imread(fname)\n",
    "        plt.imshow(im)\n",
    "    except:\n",
    "        if weights_df is None: # eg. svcca, don't need to do special division\n",
    "            df = corr_df.applymap(lambda t: float('nan') if type(t) is float else \n",
    "                                              t[:int(fl*len(t))].mean())\n",
    "        else:\n",
    "            denominator_df = weights_df.applymap(lambda t: float('nan') if type(t) is float else \n",
    "                                                             t[:int(fl*len(t))].sum())\n",
    "            df = corr_df.applymap(lambda t: float('nan') if type(t) is float else\n",
    "                                            t[:int(fl*len(t))].sum())\n",
    "            df /= denominator_df\n",
    "        sns.heatmap(df.fillna(1), vmin=0, vmax=1)\n",
    "        # sns.heatmap(df.fillna(1), )\n",
    "        plt.savefig(fname, transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive updates\n",
    "def pw_update(fl):\n",
    "    corrs_update(fl, pw_corrs_df, \"temp_pw13_\", weights_df=pw_alignments_df)\n",
    "slider = FloatSlider(min=0, max=1, step=0.1)\n",
    "interactive(pw_update, fl=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive updates\n",
    "def sv_update(fl):\n",
    "    corrs_update(fl, sv_corrs_df, \"temp_sv13_\", weights_df=None)\n",
    "slider = FloatSlider(min=0, max=1, step=0.1)\n",
    "interactive(sv_update, fl=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive for maxmincorr\n",
    "maxmin_corrs = res_d['maxcorr']['corrs']\n",
    "maxmin_corrs_df = pd.DataFrame(maxmin_corrs).applymap(lambda a: float('nan') if type(a) is float else -np.sort(-a)) # np sort has no reverse keyword\n",
    "maxmin_corrs_df = maxmin_corrs_df.reindex(network_l)\n",
    "maxmin_corrs_df = maxmin_corrs_df.reindex(network_l, axis=1)\n",
    "# maxmin_corrs_df = maxmin_corrs_df.reindex(maxmin_corrs_df.columns)\n",
    "def maxmincorr_update(fl):\n",
    "    corrs_update(fl, maxmin_corrs_df, \"temp_maxmincorr_\", weights_df=None)\n",
    "slider = FloatSlider(min=0, max=1, step=0.1)\n",
    "interactive(maxmincorr_update, fl=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive for linregcorr\n",
    "linreg_corrs = res_d['maxlinreg']['pred_power']\n",
    "linreg_corrs_df = pd.DataFrame(linreg_corrs).applymap(lambda a: float('nan') if type(a) is float else -np.sort(-a)) # np sort has no reverse keyword\n",
    "linreg_corrs_df = linreg_corrs_df.reindex(network_l)\n",
    "linreg_corrs_df = linreg_corrs_df.reindex(network_l, axis=1)\n",
    "# linreg_corrs_df = linreg_corrs_df.reindex(linreg_corrs_df.columns)\n",
    "def linregcorr_update(fl):\n",
    "    corrs_update(fl, linreg_corrs_df, \"temp_linregcorr_\", weights_df=None)\n",
    "slider = FloatSlider(min=0, max=1, step=0.1)\n",
    "interactive(linregcorr_update, fl=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbfcka\n",
    "# sns.heatmap(rbfcka_df.reindex(rbfcka_df.columns).fillna(1), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing models\n",
    "# use lincka\n",
    "model1 = \"xlnet\"\n",
    "model2 = \"xlnet\"\n",
    "cols = [s for s in lincka_df.columns if s.find(model1) >= 0]\n",
    "rows = [s for s in lincka_df.columns if s.find(model2) >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lincka_df.loc[rows, cols]\n",
    "\n",
    "sns.heatmap(df, xticklabels=range(len(df.columns)), yticklabels=range(len(df.index)), annot=True)\n",
    "plt.xlabel(model1)\n",
    "plt.ylabel(model2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
